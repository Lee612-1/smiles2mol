{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/train_data_40k.csv')\n",
    "df = df[:10]\n",
    "df.to_csv('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/train_demo.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/val_data_5k.csv')\n",
    "df = df[:125]\n",
    "df.to_csv('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/val_demo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "with open('/hpc2hdd/home/yli106/smiles2mol/config/qm9_default.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config = EasyDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [10:49<00:00, 307.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1881"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import argparse\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/hpc2hdd/home/yli106/smiles_3d/llama2_7b_chat\", trust_remote_code=True, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token # Use the EOS token to pad shorter sequences\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "max_len = 0\n",
    "for i in tqdm(range(len(df))):\n",
    "    input_text = df['text'][i]\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    if len(input_ids[0]) > max_len:\n",
    "        max_len = len(input_ids[0])\n",
    "max_len   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/test_data_200.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/hpc2hdd/home/yli106/smiles2mol/GEOM/qm9_processed/val_data_5k.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('dsaa6800': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ce6e8a217c41fb4da55841c6f4fa84b93e38c08d9863917dcf321eba60ffb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
